{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "679c1ed4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîÑ Project Flow: Sentiment Analysis of Product Reviews\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 1. **Dataset Creation**\n",
    "- A synthetic dataset is created containing 20 product reviews labeled as either `positive` or `negative`.\n",
    "- Saved as `product_reviews.csv` for reproducibility.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 2. **Text Preprocessing (NLP Pipeline)**  \n",
    "Performed using **NLTK**:\n",
    "- **Tokenization** ‚Äì Split each review into individual words (tokens).\n",
    "- **Lowercasing** ‚Äì Normalize all text to lowercase.\n",
    "- **Stopword Removal** ‚Äì Eliminate common non-informative words (e.g., ‚Äúis‚Äù, ‚Äúand‚Äù, ‚Äúthe‚Äù).\n",
    "- **Lemmatization** ‚Äì Convert words to their base/root form (e.g., ‚Äúworking‚Äù ‚Üí ‚Äúwork‚Äù).\n",
    "- **Punctuation Removal** ‚Äì Remove special characters and symbols.\n",
    "\n",
    "‚úîÔ∏è Result: Cleaned and meaningful text ready for vectorization.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 3. **Feature Extraction (TF-IDF Vectorization)**  \n",
    "- Convert cleaned reviews into numerical format using **TfidfVectorizer**.\n",
    "- Each review is now represented as a vector of weighted word frequencies.\n",
    "\n",
    "‚úîÔ∏è This step transforms raw text into a format suitable for machine learning.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 4. **Train-Test Split**\n",
    "- Dataset is split into training (75%) and testing (25%) sets using `train_test_split`.\n",
    "- Ensures models are trained and evaluated on separate data for unbiased results.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 5. **Model Training**\n",
    "Two classification models are trained:\n",
    "- **Multinomial Naive Bayes** ‚Äì Suitable for discrete data like word counts.\n",
    "- **Logistic Regression** ‚Äì A strong baseline for binary classification problems.\n",
    "\n",
    "‚úîÔ∏è Both models are fitted on the training data.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 6. **Model Evaluation**\n",
    "Each model is evaluated on the test data using:\n",
    "- **Accuracy Score** ‚Äì Overall correctness.\n",
    "- **Classification Report** ‚Äì Includes precision, recall, and F1-score for both classes.\n",
    "\n",
    "‚úîÔ∏è This helps compare performance and choose the better model.\n",
    "\n",
    "---\n",
    "\n",
    "### üîπ 7. **Predictions on New Reviews**\n",
    "- Example reviews (unseen during training) are preprocessed and vectorized.\n",
    "- Predictions are made using both trained models.\n",
    "  \n",
    "‚úîÔ∏è Shows how the models perform on real-time inputs.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2147b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11357100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a larger synthetic dataset\n",
    "data = {\n",
    "    'review': [\n",
    "        'This product is amazing and works perfectly',\n",
    "        'Terrible experience, it broke after one use',\n",
    "        'I love this item, highly recommend it',\n",
    "        'Not worth the money, very disappointing',\n",
    "        'Fantastic quality, exceeded my expectations',\n",
    "        'Poor design, stopped working quickly',\n",
    "        'Really happy with this purchase',\n",
    "        'Awful product, waste of time',\n",
    "        'Superb performance, very satisfied',\n",
    "        'Horrible, it failed immediately',\n",
    "        'Great value for the price',\n",
    "        'Bad quality, would not buy again',\n",
    "        'Excellent product, works as advertised',\n",
    "        'Disappointing, broke within days',\n",
    "        'Love the design and functionality',\n",
    "        'Worst purchase ever, totally useless',\n",
    "        'Impressive features, highly recommend',\n",
    "        'Cheaply made, fell apart fast',\n",
    "        'Amazing experience, will buy again',\n",
    "        'Terrible product, complete waste'\n",
    "    ],\n",
    "    'sentiment': ['positive', 'negative', 'positive', 'negative', 'positive', 'negative', \n",
    "                  'positive', 'negative', 'positive', 'negative', 'positive', 'negative', \n",
    "                  'positive', 'negative', 'positive', 'negative', 'positive', 'negative', \n",
    "                  'positive', 'negative']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('product_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d2dce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Text Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token.lower()) for token in tokens \n",
    "              if token.lower() not in stop_words and token not in string.punctuation]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "403031d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Reviews Sample:\n",
      "                                        review  \\\n",
      "0  This product is amazing and works perfectly   \n",
      "1  Terrible experience, it broke after one use   \n",
      "2        I love this item, highly recommend it   \n",
      "3      Not worth the money, very disappointing   \n",
      "4  Fantastic quality, exceeded my expectations   \n",
      "\n",
      "                           cleaned_review  \n",
      "0          product amazing work perfectly  \n",
      "1       terrible experience broke one use  \n",
      "2              love item highly recommend  \n",
      "3               worth money disappointing  \n",
      "4  fantastic quality exceeded expectation  \n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing and debug\n",
    "df['cleaned_review'] = df['review'].apply(preprocess_text)\n",
    "print(\"Cleaned Reviews Sample:\")\n",
    "print(df[['review', 'cleaned_review']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e165a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Vocabulary:\n",
      "['product', 'amazing', 'work', 'perfectly', 'terrible', 'experience', 'broke', 'one', 'use', 'love']\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['cleaned_review'])\n",
    "print(\"\\nTF-IDF Vocabulary:\")\n",
    "print(list(tfidf_vectorizer.vocabulary_.keys())[:10])  # Show first 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d74ada03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train-Test Split\n",
    "y = df['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79caf3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Train Models\n",
    "# Naive Bayes\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_clf = LogisticRegression(max_iter=1000)\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bee1507f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes Results:\n",
      "Accuracy: 0.6\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.33      0.50         3\n",
      "    positive       0.50      1.00      0.67         2\n",
      "\n",
      "    accuracy                           0.60         5\n",
      "   macro avg       0.75      0.67      0.58         5\n",
      "weighted avg       0.80      0.60      0.57         5\n",
      "\n",
      "\n",
      "Logistic Regression Results:\n",
      "Accuracy: 0.4\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         3\n",
      "    positive       0.40      1.00      0.57         2\n",
      "\n",
      "    accuracy                           0.40         5\n",
      "   macro avg       0.20      0.50      0.29         5\n",
      "weighted avg       0.16      0.40      0.23         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Deepanshu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Deepanshu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Deepanshu\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate Models\n",
    "print(\"\\nNaive Bayes Results:\")\n",
    "y_pred_nb = nb_clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n",
    "\n",
    "print(\"\\nLogistic Regression Results:\")\n",
    "y_pred_lr = lr_clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c753d79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Reviews Cleaned:\n",
      "['product great', 'really bad quality broke instantly']\n",
      "\n",
      "Naive Bayes Predictions:\n",
      "Review: This product is great! --> Sentiment: positive\n",
      "Review: Really bad quality, broke instantly --> Sentiment: negative\n",
      "\n",
      "Logistic Regression Predictions:\n",
      "Review: This product is great! --> Sentiment: positive\n",
      "Review: Really bad quality, broke instantly --> Sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Predict on New Reviews\n",
    "new_reviews = [\"This product is great!\", \"Really bad quality, broke instantly\"]\n",
    "new_reviews_cleaned = [preprocess_text(review) for review in new_reviews]\n",
    "new_reviews_tfidf = tfidf_vectorizer.transform(new_reviews_cleaned)\n",
    "print(\"\\nNew Reviews Cleaned:\")\n",
    "print(new_reviews_cleaned)\n",
    "\n",
    "print(\"\\nNaive Bayes Predictions:\")\n",
    "nb_predictions = nb_clf.predict(new_reviews_tfidf)\n",
    "for review, pred in zip(new_reviews, nb_predictions):\n",
    "    print(f\"Review: {review} --> Sentiment: {pred}\")\n",
    "\n",
    "print(\"\\nLogistic Regression Predictions:\")\n",
    "lr_predictions = lr_clf.predict(new_reviews_tfidf)\n",
    "for review, pred in zip(new_reviews, lr_predictions):\n",
    "    print(f\"Review: {review} --> Sentiment: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063fcedd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3190e675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52343298",
   "metadata": {},
   "source": [
    "### Learning: \n",
    "\n",
    "> Text preprocessing techniques such as tokenization, stopword removal, and lemmatization.\n",
    ">\n",
    "> Representing text data numerically using TF-IDF vectorization for machine learning.\n",
    ">\n",
    "> comparing machine learning models like Naive Bayes and Logistic Regression for classification tasks.\n",
    ">\n",
    "> Use of evaluation metrics like accuracy, precision, recall, and F1-score to assess model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584e9741",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "###  Summary\n",
    "This project demonstrates the complete lifecycle of an NLP task using classical machine learning:\n",
    "> **Raw Text ‚û°Ô∏è Cleaned Text ‚û°Ô∏è Vectorized ‚û°Ô∏è Trained ‚û°Ô∏è Evaluated ‚û°Ô∏è Predicted**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72596326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
